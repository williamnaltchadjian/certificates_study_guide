# â˜ï¸ AWS Documentation: Machine Learning: Fundamentos

Este documento cobre os fundamentos de AI e Machine Learning, tipos de aprendizado, mÃ©tricas e conceitos essenciais que costumam cair na prova.

> [!NOTE]
> Base conceitual importante para entender SageMaker e GenAI.

---

## ğŸ§  AI, ML, Deep Learning e GenAI

| Conceito | DescriÃ§Ã£o |
| :--- | :--- |
| **Artificial Intelligence (AI)** | Campo amplo que cria sistemas capazes de simular inteligÃªncia humana |
| **Machine Learning (ML)** | SubÃ¡rea da AI onde modelos aprendem padrÃµes a partir de dados |
| **Deep Learning (DL)** | SubÃ¡rea do ML baseada em redes neurais profundas |
| **Generative AI (GenAI)** | Modelos capazes de gerar conteÃºdo novo (texto, imagem, cÃ³digo) |

### ğŸ¯ RelaÃ§Ã£o:
```
AI > ML > Deep Learning > GenAI
```

---

## ğŸ“˜ ML Terms You May Encounter

Termos comuns na prova:

| Termo | DefiniÃ§Ã£o | Exemplo PrÃ¡tico |
| :--- | :--- | :--- |
| **Dataset** | Conjunto completo de dados usados no projeto de ML | Base com 10.000 registros de clientes |
| **Feature** | VariÃ¡vel de entrada usada para fazer a previsÃ£o | Idade, renda, histÃ³rico de compras |
| **Label** | Resposta correta que o modelo deve aprender | "Fraude" ou "NÃ£o Fraude" |
| **Training** | Fase em que o modelo aprende padrÃµes com os dados | Modelo aprende com 70% dos dados disponÃ­veis |
| **Validation** | Dados usados durante o treino para ajustar o modelo | Ajustar hiperparÃ¢metros com 15% dos dados |
| **Test Set** | Dados usados para avaliar o desempenho final | Avaliar modelo com 15% de dados nunca vistos |
| **Model** | Algoritmo treinado que faz previsÃµes | Modelo que prevÃª churn de clientes |
| **Inference** | Uso do modelo treinado para prever novos dados | Prever se um novo cliente vai cancelar |
| **Overfitting** | Modelo aprende demais os dados de treino e nÃ£o generaliza | 99% no treino, 70% no teste |
| **Underfitting** | Modelo simples demais, nÃ£o aprende bem | Baixa acurÃ¡cia em treino e teste |

---

## ğŸ“ MÃ©tricas de AvaliaÃ§Ã£o de Modelos

| MÃ©trica                    | O que mede                                           | Quando usar                                     | Exemplo prÃ¡tico                                          | Caso de uso real                                                       |
| :------------------------- | :--------------------------------------------------- | :---------------------------------------------- | :------------------------------------------------------- | :--------------------------------------------------------------------- |
| **AcurÃ¡cia (Accuracy)**    | % total de previsÃµes corretas                        | Quando as classes sÃ£o balanceadas               | 90 acertos em 100 e-mails â†’ 90%                          | ClassificaÃ§Ã£o de imagens onde hÃ¡ mesma quantidade de gatos e cachorros |
| **PrecisÃ£o (Precision)**   | Entre os positivos previstos, quantos estÃ£o corretos | Quando falso positivo Ã© crÃ­tico                 | 50 transaÃ§Ãµes marcadas como fraude, 45 eram fraude â†’ 90% | Sistema antifraude bancÃ¡rio (nÃ£o bloquear cliente legÃ­timo)            |
| **Recall (Sensibilidade)** | Entre os positivos reais, quantos foram detectados   | Quando falso negativo Ã© crÃ­tico                 | Detectou 80 de 100 fraudes â†’ 80%                         | DiagnÃ³stico mÃ©dico (nÃ£o deixar passar doenÃ§a real)                     |
| **F1 Score**               | EquilÃ­brio entre precisÃ£o e recall                   | Dados desbalanceados                            | PrecisÃ£o 0,8 e Recall 0,6 â†’ F1 â‰ˆ 0,69                    | DetecÃ§Ã£o de spam (balancear bloqueio e seguranÃ§a)                      |
| **AUC-ROC**                | Capacidade do modelo distinguir classes              | Comparar modelos de classificaÃ§Ã£o               | AUC = 0,95 â†’ excelente separaÃ§Ã£o                         | Escolher melhor modelo de crÃ©dito entre vÃ¡rios candidatos              |
| **MAE**                    | MÃ©dia do erro absoluto                               | RegressÃ£o quando queremos erro mÃ©dio claro      | Erro mÃ©dio de R$ 50                                      | PrevisÃ£o de preÃ§o de imÃ³veis                                           |
| **MSE**                    | MÃ©dia do erro ao quadrado                            | Quando erros grandes sÃ£o muito crÃ­ticos         | Erros grandes aumentam muito o MSE                       | PrevisÃ£o de demanda de estoque (evitar grandes falhas)                 |
| **Perplexidade**           | Qualidade da previsÃ£o da prÃ³xima palavra             | Avaliar modelos de linguagem                    | Modelo A = 15, B = 25 â†’ A melhor                         | Avaliar qualidade de um LLM                                            |
| **BLEU**                   | Similaridade com traduÃ§Ã£o de referÃªncia              | TraduÃ§Ã£o automÃ¡tica                             | TraduÃ§Ã£o prÃ³xima ao texto oficial â†’ BLEU alto            | Sistema de traduÃ§Ã£o automÃ¡tica                                         |
| **ROUGE**                  | Similaridade textual focada em recall                | Avaliar sumarizaÃ§Ã£o                             | Resumo cobre 80% das ideias                              | GeraÃ§Ã£o automÃ¡tica de resumo jurÃ­dico                                  |
| **BERTScore**              | Similaridade semÃ¢ntica usando embeddings             | Avaliar significado, nÃ£o apenas palavras iguais | Texto diferente, mesmo sentido â†’ score alto              | AvaliaÃ§Ã£o de respostas de chatbot                                      |

---

### ğŸ¯ Resumo EstratÃ©gico para Prova

| Tipo | MÃ©tricas |
| :--- | :--- |
| **ClassificaÃ§Ã£o** | Accuracy, Precision, Recall, F1, AUC |
| **RegressÃ£o** | MAE, MSE |
| **LLMs** | Perplexidade |
| **GenAI (texto)** | BLEU, ROUGE, BERTScore |

---

## ğŸ“Š Training Data

Dados usados para treinar o modelo.

### Boas prÃ¡ticas:
* Dados representativos
* Dados limpos
* Sem viÃ©s excessivo
* Quantidade suficiente

> [!IMPORTANT]
> Qualidade dos dados impacta diretamente o modelo.

---

## ğŸ§  Tipos de Aprendizado em Machine Learning

| Tipo de Aprendizado | Usa rÃ³tulo? | Objetivo | Principais CaracterÃ­sticas | Exemplos de Uso |
| :--- | :--- | :--- | :--- | :--- |
| **Supervised Learning** | âœ… Sim | Prever resultado conhecido | Usa features + labels | Spam vs nÃ£o spam (classificaÃ§Ã£o), prever preÃ§o (regressÃ£o) |
| **Unsupervised Learning** | âŒ NÃ£o | Descobrir padrÃµes ocultos | Clustering, reduÃ§Ã£o de dimensionalidade | SegmentaÃ§Ã£o de clientes |
| **Self-Supervised Learning** | âš ï¸ RÃ³tulo gerado pelo prÃ³prio modelo | Aprender representaÃ§Ã£o dos dados | Muito usado em LLMs e GenAI | Prever prÃ³xima palavra |
| **Reinforcement Learning (RL)** | âŒ NÃ£o usa rÃ³tulo tradicional | Maximizar recompensa | Baseado em agente, ambiente, recompensa e penalidade | Jogos, robÃ³tica, otimizaÃ§Ã£o |

### ğŸ¯ Dica EstratÃ©gica para Prova

* ğŸ“Œ Se tem label definido â†’ Supervised
* ğŸ“Œ Se quer descobrir padrÃµes â†’ Unsupervised
* ğŸ“Œ Se modelo cria seus prÃ³prios rÃ³tulos â†’ Self-Supervised
* ğŸ“Œ Se aprende por recompensa e tentativa/erro â†’ Reinforcement Learning

---

## ğŸ“Š Underfitting, Overfitting, Bias e VariÃ¢ncia

| Conceito | Alto Bias? | Alta VariÃ¢ncia? | Erro no Treino | Erro no Teste | DescriÃ§Ã£o | Como Melhorar |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Underfitting** | âœ… Sim | âŒ NÃ£o | Alto | Alto | Modelo simples demais, nÃ£o aprende os padrÃµes | Aumentar complexidade, adicionar features, treinar mais |
| **Overfitting** | âŒ NÃ£o | âœ… Sim | Baixo | Alto | Modelo complexo demais, aprende atÃ© o ruÃ­do | RegularizaÃ§Ã£o, mais dados, simplificar modelo |
| **Bias** | âœ… Sim | âŒ NÃ£o | Alto | Alto | Erro por simplificaÃ§Ã£o excessiva | Modelo mais complexo |
| **VariÃ¢ncia** | âŒ NÃ£o | âœ… Sim | Baixo | Alto | SensÃ­vel demais aos dados de treino | RegularizaÃ§Ã£o, mais dados |

### ğŸ¯ Leitura rÃ¡pida para prova

| SituaÃ§Ã£o | Problema | SoluÃ§Ã£o |
| :--- | :--- | :--- |
| Erro alto em treino e teste | Underfitting (Alto Bias) | Modelo mais complexo |
| Erro baixo no treino e alto no teste | Overfitting (Alta VariÃ¢ncia) | RegularizaÃ§Ã£o, mais dados |
| Erro equilibrado | Modelo adequado | Manter configuraÃ§Ã£o |

> [!IMPORTANT]
> **Objetivo:** Baixo Bias + Baixa VariÃ¢ncia = melhor generalizaÃ§Ã£o.

### ğŸ§  Regra de Ouro da Prova

* Muito Bias â†’ modelo fraco
* Muita VariÃ¢ncia â†’ modelo instÃ¡vel
* EquilÃ­brio â†’ melhor generalizaÃ§Ã£o

---

## ğŸš€ Machine Learning â€“ Inferencing

**InferÃªncia** Ã© quando o modelo jÃ¡ treinado faz previsÃµes com novos dados.

| Fase | DescriÃ§Ã£o |
| :--- | :--- |
| **Treinamento** | Aprende |
| **InferÃªncia** | Aplica o que aprendeu |

---

---

## ğŸ¯ O que Ã© Ajuste de HiperparÃ¢metros?

Ã‰ o processo de testar diferentes combinaÃ§Ãµes de hiperparÃ¢metros para encontrar a configuraÃ§Ã£o que gera o melhor desempenho do modelo.

- ğŸ”¹ Pode ser manual ou automatizado
- ğŸ”¹ Ã‰ um processo iterativo e computacionalmente caro
- ğŸ”¹ Usa mÃ©tricas (ex: accuracy, loss) para escolher o melhor conjunto

### ğŸ“Œ O que sÃ£o HiperparÃ¢metros?

SÃ£o configuraÃ§Ãµes externas definidas antes do treinamento.

- âš ï¸ NÃ£o sÃ£o aprendidos pelo modelo.
- Eles controlam estrutura, velocidade e comportamento do treino.

### ğŸ“Š HiperparÃ¢metros vs ParÃ¢metros

| Tipo | Quem define | Quando sÃ£o definidos | Exemplo |
| :--- | :--- | :--- | :--- |
| HiperparÃ¢metros | Cientista de dados | Antes do treino | Learning rate, nÂº de camadas |
| ParÃ¢metros | Modelo | Durante o treino | Pesos da rede neural |

### ğŸ“ˆ Por que o ajuste Ã© importante?

| Impacto | ExplicaÃ§Ã£o |
| :--- | :--- |
| Performance | Pode melhorar muito a precisÃ£o do modelo |
| ConvergÃªncia | Evita treino muito lento ou instÃ¡vel |
| GeneralizaÃ§Ã£o | Reduz underfitting e overfitting |

### ğŸ“Œ Exemplo clÃ¡ssico

- Learning rate muito alto â†’ converge rÃ¡pido, mas mal
- Learning rate muito baixo â†’ demora demais

### ğŸ”„ Como Funciona o Ajuste?

1. Definir mÃ©trica alvo (ex: accuracy)
2. Testar combinaÃ§Ãµes de hiperparÃ¢metros
3. Avaliar com validaÃ§Ã£o cruzada
4. Escolher melhor resultado

---

## ğŸ§ª TÃ©cnicas de Ajuste de HiperparÃ¢metros

| TÃ©cnica | Como funciona | Vantagem | Desvantagem |
| :--- | :--- | :--- | :--- |
| Grid Search | Testa todas as combinaÃ§Ãµes possÃ­veis | Simples e completo | Muito custoso |
| Random Search | Testa combinaÃ§Ãµes aleatÃ³rias | Mais eficiente que Grid | Pode perder melhor combinaÃ§Ã£o |
| OtimizaÃ§Ã£o Bayesiana | Usa probabilidade para escolher prÃ³ximas combinaÃ§Ãµes | Mais inteligente e eficiente | Mais complexa |
| Hyperband | Elimina modelos ruins cedo | Muito rÃ¡pido para deep learning | Foco em grandes modelos |

---

## ğŸ§  Exemplos de HiperparÃ¢metros Comuns

| HiperparÃ¢metro | O que controla |
| :--- | :--- |
| Learning Rate | Velocidade de aprendizado |
| Learning Rate Decay | ReduÃ§Ã£o gradual da taxa |
| Momentum | DireÃ§Ã£o do prÃ³ximo passo |
| NÂº de Camadas | Profundidade da rede |
| NÂº de NÃ³s | Complexidade da rede |
| Batch Size | Tamanho do lote de treino |
| Epochs | Quantas vezes o dataset Ã© usado |
| Eta | Controle para evitar overfitting |

---

## â˜ï¸ Como a AWS Ajuda

Amazon SageMaker oferece:

| Recurso | O que faz |
| :--- | :--- |
| Automatic Model Tuning | Ajuste automÃ¡tico de hiperparÃ¢metros |
| Bayesian Optimization | EstratÃ©gia inteligente de busca |
| Hyperband | Busca mais rÃ¡pida para modelos grandes |
| Suporte a algoritmos prÃ³prios e personalizados | Flexibilidade total |

Ele executa mÃºltiplos treinos automaticamente e escolhe o melhor modelo.

### ğŸ¯ Resumo Final para Prova

- HiperparÃ¢metros â†’ definidos antes do treino
- ParÃ¢metros â†’ aprendidos durante o treino
- Ajuste â†’ processo de otimizaÃ§Ã£o iterativa
- TÃ©cnicas principais â†’ Grid, Random, Bayesiana
- AWS automatiza isso com SageMaker

---

## ğŸ”„ Fases de um Projeto de ML

A AWS segue este fluxo lÃ³gico:

| Fase | DescriÃ§Ã£o |
| :--- | :--- |
| **1. DefiniÃ§Ã£o do Problema** | Ã‰ viÃ¡vel? Temos dados? |
| **2. PreparaÃ§Ã£o de Dados** | Limpeza e transformaÃ§Ã£o |
| **3. Treinamento** | Onde o algoritmo "estuda" |
| **4. AvaliaÃ§Ã£o** | Teste de estresse do modelo |
| **5. Deployment** | Disponibilizar para o usuÃ¡rio |

---

## ğŸš« When is ML Not Appropriate?

ML nÃ£o Ã© ideal quando:

* Regras sÃ£o simples e determinÃ­sticas
* Poucos dados disponÃ­veis
* Custo maior que benefÃ­cio
* Explicabilidade total Ã© exigida
* Problema pode ser resolvido com lÃ³gica simples

> [!TIP]
> Nem todo problema precisa de ML.

---

## ğŸ¯ Resumo EstratÃ©gico para Prova

VocÃª precisa dominar:

* DiferenÃ§a AI vs ML vs DL vs GenAI
* Supervised vs Unsupervised
* Overfitting vs Underfitting
* Bias vs Variance
* Precision vs Recall
* Treinamento vs InferÃªncia
* O que sÃ£o hiperparÃ¢metros
* Fases do ciclo de ML
* Quando NÃƒO usar ML

---





---

## ğŸ“š N-Gram

| Item | DescriÃ§Ã£o | Exemplo | Quando Usar |
| :--- | :--- | :--- | :--- |
| **DefiniÃ§Ã£o** | SequÃªncia de n palavras consecutivas em um texto | "machine learning" (bigram) | ExtraÃ§Ã£o de features de texto |
| **Unigram (n=1)** | Palavras individuais | "machine", "learning" | Modelo simples de classificaÃ§Ã£o |
| **Bigram (n=2)** | Pares de palavras consecutivas | "machine learning" | Capturar contexto curto |
| **Trigram (n=3)** | Trio de palavras consecutivas | "I love AWS" | Capturar contexto mais especÃ­fico |
| **Como funciona** | Divide texto por espaÃ§os e gera combinaÃ§Ãµes atÃ© o valor de n definido | Texto â†’ lista de tokens | PrÃ©-processamento em NLP |
| **Importante** | NÃ£o remove pontuaÃ§Ã£o automaticamente | "book!" pode virar token | Deve limpar texto antes |
| **Objetivo no ML** | Transformar texto em features numÃ©ricas | Vetores de palavras | ClassificaÃ§Ã£o, anÃ¡lise de sentimento |

### ğŸ¯ Para que serve

N-gramas ajudam modelos a capturar padrÃµes sequenciais no texto, por exemplo:

- RelaÃ§Ãµes entre palavras prÃ³ximas (ex: "not good", "very happy").
- Contexto de palavras dependendo das vizinhanÃ§as.
- CaracterÃ­sticas para classificaÃ§Ã£o de texto ou anÃ¡lise de sentimento.

SÃ£o amplamente utilizados em NLP (Processamento de Linguagem Natural) e extraÃ§Ã£o de features de texto para machine learning.

### ğŸ¯ EssÃªncia para Prova

- N-gram = sequÃªncia de palavras adjacentes
- Ajuda a capturar contexto local
- Usado em feature engineering para NLP
- Quanto maior o n â†’ mais contexto, porÃ©m maior complexidade

---

## ğŸš¨ Pegadinhas comuns

| Mito | Realidade |
| :--- | :--- |
| **Accuracy alta** | NÃ£o significa modelo bom |
| **Overfitting** | NÃ£o Ã© erro de dados, Ã© erro de generalizaÃ§Ã£o |
| **Hyperparameters** | NÃ£o sÃ£o aprendidos |
| **InferÃªncia** | NÃ£o Ã© treinamento |
| **GenAI** | Usa self-supervised learning |

---

