# â˜ï¸ AWS Documentation: Machine Learning: Fundamentos

Este documento cobre os fundamentos de AI e Machine Learning, tipos de aprendizado, mÃ©tricas e conceitos essenciais que costumam cair na prova.

> [!NOTE]
> Base conceitual importante para entender SageMaker e GenAI.

---

## ğŸ§  AI, ML, Deep Learning e GenAI

| Conceito | DescriÃ§Ã£o |
| :--- | :--- |
| **Artificial Intelligence (AI)** | Campo amplo que cria sistemas capazes de simular inteligÃªncia humana |
| **Machine Learning (ML)** | SubÃ¡rea da AI onde modelos aprendem padrÃµes a partir de dados |
| **Deep Learning (DL)** | SubÃ¡rea do ML baseada em redes neurais profundas |
| **Generative AI (GenAI)** | Modelos capazes de gerar conteÃºdo novo (texto, imagem, cÃ³digo) |

### ğŸ¯ RelaÃ§Ã£o:
```
AI > ML > Deep Learning > GenAI
```

---

## ğŸ“˜ ML Terms You May Encounter

Termos comuns na prova:

| Termo | DefiniÃ§Ã£o | Exemplo PrÃ¡tico |
| :--- | :--- | :--- |
| **Dataset** | Conjunto completo de dados usados no projeto de ML | Base com 10.000 registros de clientes |
| **Feature** | VariÃ¡vel de entrada usada para fazer a previsÃ£o | Idade, renda, histÃ³rico de compras |
| **Label** | Resposta correta que o modelo deve aprender | "Fraude" ou "NÃ£o Fraude" |
| **Training** | Fase em que o modelo aprende padrÃµes com os dados | Modelo aprende com 70% dos dados disponÃ­veis |
| **Validation** | Dados usados durante o treino para ajustar o modelo | Ajustar hiperparÃ¢metros com 15% dos dados |
| **Test Set** | Dados usados para avaliar o desempenho final | Avaliar modelo com 15% de dados nunca vistos |
| **Model** | Algoritmo treinado que faz previsÃµes | Modelo que prevÃª churn de clientes |
| **Inference** | Uso do modelo treinado para prever novos dados | Prever se um novo cliente vai cancelar |
| **Overfitting** | Modelo aprende demais os dados de treino e nÃ£o generaliza | 99% no treino, 70% no teste |
| **Underfitting** | Modelo simples demais, nÃ£o aprende bem | Baixa acurÃ¡cia em treino e teste |

---

## ğŸ“ MÃ©tricas de AvaliaÃ§Ã£o de Modelos

| MÃ©trica                    | O que mede                                           | Quando usar                                     | Exemplo prÃ¡tico                                          | Caso de uso real                                                       |
| :------------------------- | :--------------------------------------------------- | :---------------------------------------------- | :------------------------------------------------------- | :--------------------------------------------------------------------- |
| **AcurÃ¡cia (Accuracy)**    | % total de previsÃµes corretas                        | Quando as classes sÃ£o balanceadas               | 90 acertos em 100 e-mails â†’ 90%                          | ClassificaÃ§Ã£o de imagens onde hÃ¡ mesma quantidade de gatos e cachorros |
| **PrecisÃ£o (Precision)**   | Entre os positivos previstos, quantos estÃ£o corretos | Quando falso positivo Ã© crÃ­tico                 | 50 transaÃ§Ãµes marcadas como fraude, 45 eram fraude â†’ 90% | Sistema antifraude bancÃ¡rio (nÃ£o bloquear cliente legÃ­timo)            |
| **Recall (Sensibilidade)** | Entre os positivos reais, quantos foram detectados   | Quando falso negativo Ã© crÃ­tico                 | Detectou 80 de 100 fraudes â†’ 80%                         | DiagnÃ³stico mÃ©dico (nÃ£o deixar passar doenÃ§a real)                     |
| **F1 Score**               | EquilÃ­brio entre precisÃ£o e recall                   | Dados desbalanceados                            | PrecisÃ£o 0,8 e Recall 0,6 â†’ F1 â‰ˆ 0,69                    | DetecÃ§Ã£o de spam (balancear bloqueio e seguranÃ§a)                      |
| **AUC-ROC**                | Capacidade do modelo distinguir classes              | Comparar modelos de classificaÃ§Ã£o               | AUC = 0,95 â†’ excelente separaÃ§Ã£o                         | Escolher melhor modelo de crÃ©dito entre vÃ¡rios candidatos              |
| **MAE**                    | MÃ©dia do erro absoluto                               | RegressÃ£o quando queremos erro mÃ©dio claro      | Erro mÃ©dio de R$ 50                                      | PrevisÃ£o de preÃ§o de imÃ³veis                                           |
| **MSE**                    | MÃ©dia do erro ao quadrado                            | Quando erros grandes sÃ£o muito crÃ­ticos         | Erros grandes aumentam muito o MSE                       | PrevisÃ£o de demanda de estoque (evitar grandes falhas)                 |
| **Perplexidade**           | Qualidade da previsÃ£o da prÃ³xima palavra             | Avaliar modelos de linguagem                    | Modelo A = 15, B = 25 â†’ A melhor                         | Avaliar qualidade de um LLM                                            |
| **BLEU**                   | Similaridade com traduÃ§Ã£o de referÃªncia              | TraduÃ§Ã£o automÃ¡tica                             | TraduÃ§Ã£o prÃ³xima ao texto oficial â†’ BLEU alto            | Sistema de traduÃ§Ã£o automÃ¡tica                                         |
| **ROUGE**                  | Similaridade textual focada em recall                | Avaliar sumarizaÃ§Ã£o                             | Resumo cobre 80% das ideias                              | GeraÃ§Ã£o automÃ¡tica de resumo jurÃ­dico                                  |
| **BERTScore**              | Similaridade semÃ¢ntica usando embeddings             | Avaliar significado, nÃ£o apenas palavras iguais | Texto diferente, mesmo sentido â†’ score alto              | AvaliaÃ§Ã£o de respostas de chatbot                                      |

---

### ğŸ¯ Resumo EstratÃ©gico para Prova

| Tipo | MÃ©tricas |
| :--- | :--- |
| **ClassificaÃ§Ã£o** | Accuracy, Precision, Recall, F1, AUC |
| **RegressÃ£o** | MAE, MSE |
| **LLMs** | Perplexidade |
| **GenAI (texto)** | BLEU, ROUGE, BERTScore |

---

## ğŸ“Š Training Data

Dados usados para treinar o modelo.

### Boas prÃ¡ticas:
* Dados representativos
* Dados limpos
* Sem viÃ©s excessivo
* Quantidade suficiente

> [!IMPORTANT]
> Qualidade dos dados impacta diretamente o modelo.

---

## ğŸ§  Tipos de Aprendizado em Machine Learning

| Tipo de Aprendizado | Usa rÃ³tulo? | Objetivo | Principais CaracterÃ­sticas | Exemplos de Uso |
| :--- | :--- | :--- | :--- | :--- |
| **Supervised Learning** | âœ… Sim | Prever resultado conhecido | Usa features + labels | Spam vs nÃ£o spam (classificaÃ§Ã£o), prever preÃ§o (regressÃ£o) |
| **Unsupervised Learning** | âŒ NÃ£o | Descobrir padrÃµes ocultos | Clustering, reduÃ§Ã£o de dimensionalidade | SegmentaÃ§Ã£o de clientes |
| **Self-Supervised Learning** | âš ï¸ RÃ³tulo gerado pelo prÃ³prio modelo | Aprender representaÃ§Ã£o dos dados | Muito usado em LLMs e GenAI | Prever prÃ³xima palavra |
| **Reinforcement Learning (RL)** | âŒ NÃ£o usa rÃ³tulo tradicional | Maximizar recompensa | Baseado em agente, ambiente, recompensa e penalidade | Jogos, robÃ³tica, otimizaÃ§Ã£o |

### ğŸ¯ Dica EstratÃ©gica para Prova

* ğŸ“Œ Se tem label definido â†’ Supervised
* ğŸ“Œ Se quer descobrir padrÃµes â†’ Unsupervised
* ğŸ“Œ Se modelo cria seus prÃ³prios rÃ³tulos â†’ Self-Supervised
* ğŸ“Œ Se aprende por recompensa e tentativa/erro â†’ Reinforcement Learning

---

## ğŸ“Š Underfitting, Overfitting, Bias e VariÃ¢ncia

| Conceito | Alto Bias? | Alta VariÃ¢ncia? | Erro no Treino | Erro no Teste | DescriÃ§Ã£o | Como Melhorar |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Underfitting** | âœ… Sim | âŒ NÃ£o | Alto | Alto | Modelo simples demais, nÃ£o aprende os padrÃµes | Aumentar complexidade, adicionar features, treinar mais |
| **Overfitting** | âŒ NÃ£o | âœ… Sim | Baixo | Alto | Modelo complexo demais, aprende atÃ© o ruÃ­do | RegularizaÃ§Ã£o, mais dados, simplificar modelo |
| **Bias** | âœ… Sim | âŒ NÃ£o | Alto | Alto | Erro por simplificaÃ§Ã£o excessiva | Modelo mais complexo |
| **VariÃ¢ncia** | âŒ NÃ£o | âœ… Sim | Baixo | Alto | SensÃ­vel demais aos dados de treino | RegularizaÃ§Ã£o, mais dados |

### ğŸ¯ Leitura rÃ¡pida para prova

| SituaÃ§Ã£o | Problema | SoluÃ§Ã£o |
| :--- | :--- | :--- |
| Erro alto em treino e teste | Underfitting (Alto Bias) | Modelo mais complexo |
| Erro baixo no treino e alto no teste | Overfitting (Alta VariÃ¢ncia) | RegularizaÃ§Ã£o, mais dados |
| Erro equilibrado | Modelo adequado | Manter configuraÃ§Ã£o |

> [!IMPORTANT]
> **Objetivo:** Baixo Bias + Baixa VariÃ¢ncia = melhor generalizaÃ§Ã£o.

### ğŸ§  Regra de Ouro da Prova

* Muito Bias â†’ modelo fraco
* Muita VariÃ¢ncia â†’ modelo instÃ¡vel
* EquilÃ­brio â†’ melhor generalizaÃ§Ã£o

---

## ğŸš€ Machine Learning â€“ Inferencing

**InferÃªncia** Ã© quando o modelo jÃ¡ treinado faz previsÃµes com novos dados.

| Fase | DescriÃ§Ã£o |
| :--- | :--- |
| **Treinamento** | Aprende |
| **InferÃªncia** | Aplica o que aprendeu |

---

## âš™ Hyperparameters

ConfiguraÃ§Ãµes definidas antes do treino.

### Exemplos:
* Learning rate
* NÃºmero de camadas
* NÃºmero de Ã¡rvores
* Batch size

> [!IMPORTANT]
> SÃ£o ajustados para melhorar desempenho, mas **nÃ£o sÃ£o aprendidos pelo modelo**.

---

## ğŸ”„ Fases de um Projeto de ML

A AWS segue este fluxo lÃ³gico:

| Fase | DescriÃ§Ã£o |
| :--- | :--- |
| **1. DefiniÃ§Ã£o do Problema** | Ã‰ viÃ¡vel? Temos dados? |
| **2. PreparaÃ§Ã£o de Dados** | Limpeza e transformaÃ§Ã£o |
| **3. Treinamento** | Onde o algoritmo "estuda" |
| **4. AvaliaÃ§Ã£o** | Teste de estresse do modelo |
| **5. Deployment** | Disponibilizar para o usuÃ¡rio |

---

## ğŸš« When is ML Not Appropriate?

ML nÃ£o Ã© ideal quando:

* Regras sÃ£o simples e determinÃ­sticas
* Poucos dados disponÃ­veis
* Custo maior que benefÃ­cio
* Explicabilidade total Ã© exigida
* Problema pode ser resolvido com lÃ³gica simples

> [!TIP]
> Nem todo problema precisa de ML.

---

## ğŸ¯ Resumo EstratÃ©gico para Prova

VocÃª precisa dominar:

* DiferenÃ§a AI vs ML vs DL vs GenAI
* Supervised vs Unsupervised
* Overfitting vs Underfitting
* Bias vs Variance
* Precision vs Recall
* Treinamento vs InferÃªncia
* O que sÃ£o hiperparÃ¢metros
* Fases do ciclo de ML
* Quando NÃƒO usar ML

---

## ğŸš¨ Pegadinhas comuns

| Mito | Realidade |
| :--- | :--- |
| **Accuracy alta** | NÃ£o significa modelo bom |
| **Overfitting** | NÃ£o Ã© erro de dados, Ã© erro de generalizaÃ§Ã£o |
| **Hyperparameters** | NÃ£o sÃ£o aprendidos |
| **InferÃªncia** | NÃ£o Ã© treinamento |
| **GenAI** | Usa self-supervised learning |

---

