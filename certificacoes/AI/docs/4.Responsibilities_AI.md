# â˜ï¸ AWS Documentation: Responsabilidades em IA

Este repositÃ³rio centraliza o conhecimento sobre riscos, desafios e responsabilidades no uso de IA e GenAI.

---

## ğŸ§  IntroduÃ§Ã£o

Esta seÃ§Ã£o aborda os riscos, desafios e responsabilidades no uso de IA e GenAI.

### Foco principal:
* Uso Ã©tico
* SeguranÃ§a
* GovernanÃ§a
* Compliance
* Monitoramento contÃ­nuo

> [!IMPORTANT]
> Ã‰ uma parte importante da prova.

---

## ğŸŸ£ AI Challenges and Responsibilities â€“ Overview

### Principais desafios da IA:
* ViÃ©s (bias)
* Falta de explicabilidade
* Privacidade de dados
* SeguranÃ§a
* AlucinaÃ§Ã£o (em GenAI)
* Uso indevido

### Responsabilidade envolve:
* Desenvolver IA de forma Ã©tica
* Garantir transparÃªncia
* Reduzir riscos

---

## ğŸŸ¢ Responsible AI

Responsible AI significa desenvolver e usar IA de forma:

* Justa (fairness)
* Transparente
* Segura
* ExplicÃ¡vel
* Privada
* ConfiÃ¡vel

### PrincÃ­pios comuns:
| PrincÃ­pio | DescriÃ§Ã£o |
| :--- | :--- |
| **Fairness** | Evitar discriminaÃ§Ã£o |
| **Explainability** | Explicabilidade |
| **Accountability** | Responsabilidade |
| **Privacy** | Privacidade |
| **Security** | SeguranÃ§a |
| **Robustness** | Robustez |

### Na AWS, ferramentas como:
* SageMaker Clarify (viÃ©s e explicabilidade)
* Guardrails no Bedrock
* Model Cards

> [!NOTE]
> Ajudam nessa governanÃ§a.

---

## ğŸŸ¡ GenAI Challenges

Desafios especÃ­ficos da IA Generativa:

| Desafio | DescriÃ§Ã£o |
| :--- | :--- |
| **Hallucinations** | Modelo inventa informaÃ§Ãµes |
| **Toxicidade** | GeraÃ§Ã£o de conteÃºdo ofensivo |
| **Prompt Injection** | UsuÃ¡rio tenta manipular o modelo para burlar regras |
| **Data Leakage** | ExposiÃ§Ã£o de dados sensÃ­veis |
| **Deepfakes** | ConteÃºdo sintÃ©tico enganoso |

### MitigaÃ§Ã£o:
* RAG
* Guardrails
* Monitoramento
* Controle de acesso

---

## ğŸŸ  Compliance for AI

Compliance garante que o uso de IA:

* Siga leis e regulaÃ§Ãµes
* Respeite LGPD/GDPR
* Proteja dados pessoais
* Mantenha registros auditÃ¡veis

### Envolve:
* DocumentaÃ§Ã£o de modelos
* Registro de decisÃµes
* Controles internos

---

## ğŸ”´ Governance for AI

GovernanÃ§a de IA significa definir:

* PolÃ­ticas
* Processos
* PapÃ©is e responsabilidades
* Monitoramento contÃ­nuo

### Inclui:
* AvaliaÃ§Ã£o de risco
* AprovaÃ§Ã£o de modelos
* Controle de versÃµes
* Auditoria

### Ferramentas como:
* Model Cards
* Model Monitor
* Pipelines

> [!TIP]
> Apoiam governanÃ§a.

---

## ğŸ” Security and Privacy for AI

### Riscos de seguranÃ§a:
* Acesso nÃ£o autorizado
* Vazamento de dados
* Ataques adversariais
* Prompt injection

### Boas prÃ¡ticas:
* IAM e controle de acesso
* Criptografia
* Isolamento de dados
* Monitoramento
* RevisÃ£o de logs

### Privacidade envolve:
* MinimizaÃ§Ã£o de dados
* Mascaramento
* Consentimento

---

## ğŸ§© GenAI Security Scoping Matrix

Matriz que ajuda a definir responsabilidades de seguranÃ§a entre:

* Cliente
* Provedor de nuvem

### Analisa:
* Dados de entrada
* Modelo
* Infraestrutura
* SaÃ­da do modelo

> [!NOTE]
> Baseada no modelo de responsabilidade compartilhada da AWS.

---

## ğŸ”„ MLOps

MLOps Ã© a prÃ¡tica de aplicar DevOps ao Machine Learning.

### Inclui:
* Versionamento de modelos
* AutomaÃ§Ã£o de pipelines
* Monitoramento de performance
* Retreinamento contÃ­nuo
* CI/CD para ML

### Objetivo:
Garantir que modelos em produÃ§Ã£o sejam:

* ConfiÃ¡veis
* Monitorados
* Atualizados
* Governados

---

## ğŸ¯ Resumo EstratÃ©gico para Prova

VocÃª precisa saber:

* O que Ã© Responsible AI
* DiferenÃ§a entre viÃ©s e hallucination
* O que Ã© prompt injection
* Conceito de responsabilidade compartilhada
* ImportÃ¢ncia de governanÃ§a
* O que Ã© MLOps

---

## ğŸš¨ Pegadinhas comuns

| Mito | Realidade |
| :--- | :--- |
| **SeguranÃ§a** | â‰  apenas criptografia |
| **Responsible AI** | â‰  apenas evitar viÃ©s |
| **Compliance** | â‰  governanÃ§a (sÃ£o complementares) |
| **Hallucination** | â‰  bias |
